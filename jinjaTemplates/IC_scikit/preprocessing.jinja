{% if scale_mean_std %}
# Set up scaler.
scaler = sklearn.preprocessing.StandardScaler()

{% endif %}
def preprocess(data, name):
    if data is None:  # val/test can be empty
        return None
    {% if data_format == "Image files" %}
    # Read image files to pytorch dataset (only temporary).
    transform = transforms.Compose([
        transforms.Resize({{ resize_pixels }}), 
        transforms.CenterCrop({{ crop_pixels }}), 
        transforms.ToTensor()
    ])
    data = datasets.ImageFolder(data, transform=transform)

    # Convert to numpy arrays.
    images_shape = (len(data), *data[0][0].shape)
    images = np.zeros(images_shape)
    labels = np.zeros(len(data))
    for i, (image, label) in enumerate(data):
        images[i] = image
        labels[i] = label
    
    {% elif data_format == "Numpy arrays" %}
    images, labels = data

    {% endif %}
    # Flatten.
    images = images.reshape(len(images), -1)

    {% if scale_mean_std %}
    # Scale to mean 0 and std 1.
    if name == "train":
        scaler.fit(images)
    images = scaler.transform(images)

    {% endif %}
    # Shuffle train set.
    if name == "train":
        images, labels = sklearn.utils.shuffle(images, labels)

    return [images, labels]

processed_train_data = preprocess(train_data, "train")
processed_val_data = preprocess(val_data, "val")
processed_test_data = preprocess(test_data, "test")